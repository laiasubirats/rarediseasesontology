{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "['Name']\n",
      "df_2 (25, 24)\n",
      "Index(['Age', 'Country', 'Disease', 'Age of Diagnosis', 'Treatment',\n",
      "       'InterestedIn', 'FacilitatorTechCommunication',\n",
      "       'RemunerativeEmployment', 'BarrierHealthProfessionals',\n",
      "       'EmotionalFunctions', 'Non-RemunerativeEmployment', 'Consciousness',\n",
      "       'Vomiting', 'Respiratory functions', 'Skin functions',\n",
      "       'Hearing and Vestibular Function', 'Financial Assets', 'Health systems',\n",
      "       'Higher Education', 'Cognitive Functions', 'Pain in head and neck',\n",
      "       'Sports', 'Arts and culture', 'Walking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import truediv\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "get_ipython().magic('matplotlib')\n",
    "\n",
    "df=pd.read_csv('C:/Scenarios about Rare Diseases_2017_08_09.csv',sep=\";\",encoding=\"latin1\")\n",
    "to_del = ['Name']\n",
    "print (to_del)\n",
    "filtered_cols = [c for c in df.columns if (c not in to_del) ]#and ('ENF' not in c)\n",
    "df_2 = df[filtered_cols]\n",
    "\n",
    "print (\"df_2\",df_2.shape)\n",
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Country', 'Disease', 'Age of Diagnosis', 'Treatment',\n",
      "       'InterestedIn', 'FacilitatorTechCommunication',\n",
      "       'RemunerativeEmployment', 'BarrierHealthProfessionals',\n",
      "       'EmotionalFunctions', 'Non-RemunerativeEmployment', 'Consciousness',\n",
      "       'Vomiting', 'Respiratory functions', 'Skin functions',\n",
      "       'Hearing and Vestibular Function', 'Financial Assets', 'Health systems',\n",
      "       'Higher Education', 'Cognitive Functions', 'Pain in head and neck',\n",
      "       'Sports', 'Arts and culture', 'Walking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['Age', 'Age of Diagnosis', 'FacilitatorTechCommunication',\n",
      "       'RemunerativeEmployment', 'BarrierHealthProfessionals',\n",
      "       'EmotionalFunctions', 'Non-RemunerativeEmployment', 'Consciousness',\n",
      "       'Vomiting', 'Respiratory functions', 'Skin functions',\n",
      "       'Hearing and Vestibular Function', 'Financial Assets', 'Health systems',\n",
      "       'Higher Education', 'Cognitive Functions', 'Pain in head and neck',\n",
      "       'Sports', 'Arts and culture', 'Walking', 'Country_France',\n",
      "       'Country_Iran', 'Country_Sierra Leone', 'Country_Spain',\n",
      "       'Disease_Acute Lymphoblastic Leukaemia', 'Disease_Algoneurodystrophy',\n",
      "       'Disease_Arthropathy in hypersensitivity reactions classified elsewhere',\n",
      "       'Disease_Benign intracranial hypertension',\n",
      "       'Disease_Cerebral arteritis, not elsewhere classified',\n",
      "       'Disease_Congenital malformation short stature',\n",
      "       'Disease_Congenital malformation syndromes predominantly affecting facial appearance',\n",
      "       'Disease_Congenital malformation syndromes predominantly involving limbs',\n",
      "       'Disease_Craniofacial dysostosis', 'Disease_Dup15q',\n",
      "       'Disease_Epidermolysis bullosa', 'Disease_Gangliosidosis',\n",
      "       'Disease_Guillain-BarrÃ© syndrome',\n",
      "       'Disease_Malignant neoplasms of eye, brain and other parts of central nervous system',\n",
      "       'Disease_Monkeypox', 'Disease_Multiple system atrophy, cerebellar type',\n",
      "       'Disease_Myasthenia gravis',\n",
      "       'Disease_Non-neuropathic heredofamilial amyloidosis', 'Disease_None',\n",
      "       'Disease_Other sphingolipidosis', 'Treatment_Chemotherapy',\n",
      "       'Treatment_None', 'Treatment_Plastical surgery',\n",
      "       'Treatment_Several operations', 'Treatment_Tracheotomy',\n",
      "       'InterestedIn_Rare Diseases', 'InterestedIn_Wolfram Syndrome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(type(df_2))\n",
    "df_3 = pd.get_dummies( data=df_2,columns=['Country','Disease','Treatment','InterestedIn'])\n",
    "print(df_3.columns)\n",
    "for i in range(0,df_3.shape[0]):\n",
    "    if (df_3.loc[i,'Age of Diagnosis']=='None'):\n",
    "        df_3.loc[i,'Age of Diagnosis']=\"NaN\"\n",
    "df_3['Age']=df_3['Age'].astype(float)\n",
    "df_3['Age of Diagnosis']=df_3['Age of Diagnosis'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (25, 51)\n",
      "Num pca_comps per > 0.8 ratio: 13 0.803982782505\n",
      "Explained variance first 2 components 0.321772935951\n",
      "51\n",
      "0.321772935951\n",
      "PCA+K-means: 13\n"
     ]
    }
   ],
   "source": [
    "#Fill na\n",
    "df_4 = df_3.fillna(value=np.mean(df_3,axis=0),inplace=False,axis=0).values\n",
    "scaler = preprocessing.MinMaxScaler().fit(df_4)\n",
    "data = scaler.transform(df_4)\n",
    "print (\"data\",data.shape)\n",
    "thrd = 0.8\n",
    "total = 0\n",
    "pca = PCA().fit(data)\n",
    "reduced_data = pca.transform(data)\n",
    "for pca_comps,r in enumerate(pca.explained_variance_ratio_):\n",
    "    if total > thrd:\n",
    "        break\n",
    "    total += r\n",
    "print (\"Num pca_comps per >\", thrd,\"ratio:\", pca_comps, total)\n",
    "print (\"Explained variance first 2 components\",pca.explained_variance_ratio_[0]+pca.explained_variance_ratio_[1])\n",
    "print (pca.n_components_)\n",
    "print (np.sum(pca.explained_variance_ratio_[:2]))\n",
    "\n",
    "print (\"PCA+K-means:\", pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.24243515601\n",
      "For n_clusters = 2  the average metrics.calinski_harabaz_score is : 6.3768639144\n",
      "For n_clusters = 3 The average silhouette_score is : 0.2898603087\n",
      "For n_clusters = 3  the average metrics.calinski_harabaz_score is : 6.52424963582\n",
      "For n_clusters = 4 The average silhouette_score is : 0.323897848518\n",
      "For n_clusters = 4  the average metrics.calinski_harabaz_score is : 5.94745653135\n",
      "For n_clusters = 5 The average silhouette_score is : 0.249692240674\n",
      "For n_clusters = 5  the average metrics.calinski_harabaz_score is : 5.69772301874\n",
      "For n_clusters = 6 The average silhouette_score is : 0.185685543781\n",
      "For n_clusters = 6  the average metrics.calinski_harabaz_score is : 5.49043933528\n",
      "For n_clusters = 7 The average silhouette_score is : 0.257798782989\n",
      "For n_clusters = 7  the average metrics.calinski_harabaz_score is : 5.95852242264\n",
      "For n_clusters = 8 The average silhouette_score is : 0.295845869636\n",
      "For n_clusters = 8  the average metrics.calinski_harabaz_score is : 6.4350352421\n",
      "For n_clusters = 9 The average silhouette_score is : 0.268947612598\n",
      "For n_clusters = 9  the average metrics.calinski_harabaz_score is : 6.64350254949\n",
      "For n_clusters = 10 The average silhouette_score is : 0.269063150609\n",
      "For n_clusters = 10  the average metrics.calinski_harabaz_score is : 6.89280187311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "for k in range(2,11):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(reduced_data[:,:pca_comps])\n",
    "    #cluster_labels=kmeans.fit(reduced_data[:,:2])\n",
    "    silhouette_avg = silhouette_score(reduced_data[:,:pca_comps], cluster_labels)\n",
    "    #silhouette_avg = silhouette_score(reduced_data[:,:2], cluster_labels)\n",
    "    print(\"For n_clusters =\", k, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    calinski_harabaz_score_avg = metrics.calinski_harabaz_score(reduced_data[:,:pca_comps], cluster_labels)\n",
    "    #calinski_harabaz_score_avg = metrics.calinski_harabaz_score(reduced_data[:,:2], cluster_labels)\n",
    "    print(\"For n_clusters =\", k,\" the average metrics.calinski_harabaz_score is :\", calinski_harabaz_score_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "pca = PCA().fit(data)\n",
    "cluster_labels = kmeans.fit_predict(reduced_data[:,:2])\n",
    "plt.figure()\n",
    "plt.plot(range(len(pca.explained_variance_ratio_)), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.axvline(pca_comps, color=\"red\")  \n",
    "plt.ylim(0.0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_data = pca.transform(data)\n",
    "#print (\"Reduced data: \",reduced_data.shape)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(reduced_data[:,:2])\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min()-.05, reduced_data[:, 0].max()+.05\n",
    "y_min, y_max = reduced_data[:, 1].min()-.05, reduced_data[:, 1].max()+.05\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(10,10))\n",
    "#plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap= plt.cm.Pastel2,#cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "#plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=4)\n",
    "\n",
    "#listA=df[df['readmitted'] == 0].index\n",
    "#plt.plot(reduced_data[listA, 0], reduced_data[listA, 1],'k.', markersize=4, c='g', label='No Readmitted')\n",
    "#listB=df[df['readmitted'] == 29].index\n",
    "#plt.plot(reduced_data[listB, 0],reduced_data[listB, 1],'k.', markersize=4, c='r',label ='<30')\n",
    "#listC=df[df['readmitted'] == 31].index\n",
    "#plt.plot(reduced_data[listC, 0],reduced_data[listC, 1],'k.', markersize=4, c='b',label ='>30')\n",
    "\n",
    "listA=df_3[df_3['Country_Spain'] == 1].index\n",
    "plt.plot(reduced_data[listA, 0], reduced_data[listA, 1],'k.', markersize=4, c='r', label='Spain')\n",
    "listB=df_3[df_3['Country_Spain'] == 0].index\n",
    "plt.plot(reduced_data[listB, 0],reduced_data[listB, 1],'k.', markersize=4, c='g',label ='Not Spain')\n",
    "\n",
    "#Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
    "#       'Chronic_pulmonary_disease', 'Myocardial_infarction',\n",
    "#       'Congestive_heart_failure'\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[0, 0], centroids[0, 1],\n",
    "            marker='>', s=169, linewidths=3, \n",
    "            color='black', zorder=10)\n",
    "plt.scatter(centroids[1, 0], centroids[1, 1],\n",
    "            marker='H', s=169, linewidths=3, \n",
    "            color='black', zorder=10)\n",
    "plt.scatter(centroids[2, 0], centroids[2, 1],\n",
    "            marker='>', s=169, linewidths=3, \n",
    "            color='blue', zorder=10)\n",
    "plt.scatter(centroids[3, 0], centroids[3, 1],\n",
    "            marker='H', s=169, linewidths=3, \n",
    "            color='blue', zorder=10)\n",
    "plt.title('K-means clustering on the rare diseases dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average Age =  [26.600000000000001, 15.285714285714286, 23.0, 23.0]\n",
      "cluster_sizes =  [15, 7, 1, 2]\n",
      "country_Spain =  [15, 0, 0, 2]\n",
      "cluster_sizes =  [15, 7, 1, 2]\n",
      "country_Iran =  [0, 3, 0, 0]\n",
      "cluster_sizes =  [15, 7, 1, 2]\n",
      "country_France =  [0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "n_clusters=4\n",
    "num_age = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    #print(df_4[i][df_3.columns.get_loc(\"Age\")])\n",
    "    #print(num_age[cluster_labels[i]])\n",
    "    num_age[cluster_labels[i]] = num_age[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(\"Age\")]\n",
    "mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "print (\"average Age = \", list(map(truediv,num_age,mida_cluster)))\n",
    "\n",
    "num_Myocardial_infarction = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Country_Spain\")] == 1):\n",
    "        num_Myocardial_infarction[cluster_labels[i]] = num_Myocardial_infarction[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"country_Spain = \", num_Myocardial_infarction)\n",
    "\n",
    "num_Myocardial_infarction = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Country_Iran\")] == 1):\n",
    "        num_Myocardial_infarction[cluster_labels[i]] = num_Myocardial_infarction[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"country_Iran = \", num_Myocardial_infarction)\n",
    "\n",
    "num_Myocardial_infarction = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Country_France\")] == 1):\n",
    "        num_Myocardial_infarction[cluster_labels[i]] = num_Myocardial_infarction[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"country_France = \", num_Myocardial_infarction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country_Spain :  [1.0, 0.0, 1.0, 0.0] , p-value:  0.0\n",
      "Country_Iran :  [0.0, 0.42857142857142855, 0.0, 0.0] , p-value:  0.00451667389589\n",
      "Age :  [26.600000000000001, 15.285714285714286, 23.0, 23.0] , p-value:  0.0393183110534\n"
     ]
    }
   ],
   "source": [
    "#P-values of attributes of each cluster\n",
    "import scipy.stats as stats\n",
    "#true_mu = 0\n",
    "listaA=df_3.columns.tolist()\n",
    "cluster1=df_4[kmeans.labels_==0]\n",
    "cluster2=df_4[kmeans.labels_==1]\n",
    "cluster_labels=kmeans.labels_\n",
    "#print(cluster1.shape)\n",
    "#print(cluster2.shape)\n",
    "contador=0\n",
    "for z in range(0,len(df_3.columns.tolist())):\n",
    "    two_sample = stats.ttest_ind(cluster1[:,z],cluster2[:,z])\n",
    "    if(two_sample[1]<0.05):contador=contador+1\n",
    "\n",
    "w, h = 3, contador\n",
    "Matrix = [[0.0 for x in range(w)] for y in range(h)] \n",
    "i=0\n",
    "for z in range(0,len(df_3.columns.tolist())):\n",
    "    #print(df_2.loc[1,z])\n",
    "    #print(np.std(cluster1[:,z]))\n",
    "    #print(df_2.values[:,z])\n",
    "    two_sample = stats.ttest_ind(cluster1[:,z],cluster2[:,z])\n",
    "    #two_sample = stats.chisquare(cluster1[:,8],cluster2[:,8])\n",
    "    if(two_sample[1]<0.05): \n",
    "        #print(i)\n",
    "        Matrix[i][0]=listaA[z]\n",
    "        Matrix[i][1]='{0:.400f}'.format(two_sample[1])\n",
    "        Matrix[i][2]=two_sample[1]\n",
    "        i=i+1\n",
    "arr = np.array(Matrix)\n",
    "arr = arr[arr[:,1].argsort()]\n",
    "#print(arr)\n",
    "\n",
    "for z in range(0,h):\n",
    "    if (0<1):\n",
    "        num_hipertensos = [0] * n_clusters\n",
    "        for i in range(len(data[:,:2])):\n",
    "            num_hipertensos[cluster_labels[i]] = num_hipertensos[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(arr[z,0])]\n",
    "        mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "        print ((arr[z,0]),\": \", list(map(truediv,num_hipertensos,mida_cluster)),\", p-value: \",arr[z,2])\n",
    "    else:\n",
    "        num_hipertensos = [0] * n_clusters\n",
    "        for i in range(len(data[:,:2])):\n",
    "            #print(\"z\",z)\n",
    "            #print(\"i\",i)\n",
    "            if (data[i][df_3.columns.get_loc(arr[z,0])] == 1):\n",
    "                num_hipertensos[cluster_labels[i]] = num_hipertensos[cluster_labels[i]] + 1\n",
    "        mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "        percentage=list(map(truediv,num_hipertensos,mida_cluster))\n",
    "        percentage[0]=round(percentage[0],2)\n",
    "        percentage[1]=round(percentage[1],2)\n",
    "        print ((arr[z,0]),\": \", num_hipertensos,\", percentage: \",percentage, \"p-value: \",arr[z,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
